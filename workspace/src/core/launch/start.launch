<launch>
    <env name="ROS_MASTER_URI" value="http://192.168.1.151:11311" />
    <env name="ROS_IP" value="192.168.1.151" />
    <!-- Запуск LL || /cmd_vel -> arduino || mobile_robot_ros_driver -->
    <include file="$(find mobile_robot_ros_driver)/launch/bringup.launch" />
    


    
    <!-- LIDAR -->
    <include file="$(find ldlidar_stl_ros)/launch/ld19.launch" />

    <!-- RealSense -->
    <param name="enable_pointcloud" value="true"/> 
    <include file="$(find realsense2_camera)/launch/rs_camera.launch" />

    <!-- Отлично, у нас есть /cmd_vel для команд управления и /camera1/image с картиной с камеры -->
    <!-- Теперь можно запускать свои и заимствованые ноды -->

    <!-- ORB Slam нода  -->
    <!-- <include file="$(find orb_slam2_ros)/ros/launch/orb_slam_mono1.launch" /> -->

    <!-- Yolo в росе нода  -->
    <!--<node pkg="core" type="yolo_in_ros.py" name="nn"
            output="screen">
    </node>--> 
        <!-- Отправка в нейронку -->
    <!-- <node pkg="core" type="gstream_out.py" name="nn1_out"
        output="screen">
    </node> -->
        <!-- Прием из нейронки -->
    <!-- <node pkg="core" type="gstream_in.py" name="nn1_in"
        output="screen">
    </node>  -->
    
    <!-- transforms -->
    <node pkg="tf2_ros" type="static_transform_publisher" name="base_to_realsense"
      args="0.07 0 0.05 0 0 0 base_link camera_link" />


</launch>
